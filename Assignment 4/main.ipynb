{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5dc91d5-c618-4f0e-a31a-0b0271cf074a",
   "metadata": {},
   "outputs": [
    {
     "ename": "LogicError",
     "evalue": "cuFuncSetBlockShape failed: invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m start_computation_gpu\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Launch kernel\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[43mleft_rotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#################### End computation GPU timing\u001b[39;00m\n\u001b[1;32m     60\u001b[0m end_computation_gpu\u001b[38;5;241m.\u001b[39mrecord()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pycuda/driver.py:481\u001b[0m, in \u001b[0;36m_add_functionality.<locals>.function_call\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust specify block size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 481\u001b[0m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_block_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m handlers, arg_buf \u001b[38;5;241m=\u001b[39m _build_arg_buf(args)\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n",
      "\u001b[0;31mLogicError\u001b[0m: cuFuncSetBlockShape failed: invalid argument"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "import time \n",
    "\n",
    "# Initialize input array with size=1024 since it's the highest and allows us to see the more differences\n",
    "# We do not time this since it is the imput creation\n",
    "input_size = 1024\n",
    "host_array = np.random.randint(low=0, high=10, size=input_size, dtype=np.int32)\n",
    "\n",
    "start_full_gpu = cuda.Event()\n",
    "end_full_gpu = cuda.Event()\n",
    "end_kernel_gpu = cuda.Event()\n",
    "start_computation_gpu = cuda.Event()\n",
    "end_computation_gpu = cuda.Event()\n",
    "\n",
    "#################### Satrt GPU timing\n",
    "start_full_gpu.record()\n",
    "\n",
    "# CUDA kernel for left rotation\n",
    "kernel_code = \"\"\"\n",
    "__global__ void left_rotation(int *in, int *out, int size) {\n",
    "    // int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    // Since we assume that there's only one block with 1024 threads we can just use the following\n",
    "    int idx = threadIdx.x;\n",
    "    if (idx < size) {\n",
    "        int shifted_idx = (idx - 1 + size) % size;\n",
    "        out[shifted_idx] = in[idx];\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the CUDA kernel\n",
    "mod = SourceModule(kernel_code)\n",
    "left_rotation = mod.get_function(\"left_rotation\")\n",
    "\n",
    "#################### End kernel GPU timing\n",
    "end_kernel_gpu.record()\n",
    "\n",
    "# Allocate memory on GPU\n",
    "device_array = cuda.mem_alloc(host_array.nbytes)\n",
    "device_output = cuda.mem_alloc(host_array.nbytes)\n",
    "\n",
    "# Copy data to GPU\n",
    "cuda.memcpy_htod(device_array, host_array)\n",
    "\n",
    "# Define block and grid size\n",
    "# Since we assume only one block with 1024 threads\n",
    "block_size = input_size\n",
    "grid_size = 1\n",
    "\n",
    "#################### Start computation GPU timing\n",
    "start_computation_gpu.record()\n",
    "# Launch kernel\n",
    "left_rotation(device_array, device_output, np.int32(input_size), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "#################### End computation GPU timing\n",
    "end_computation_gpu.record()\n",
    "\n",
    "# Copy result back to CPU\n",
    "host_output = np.empty_like(host_array)\n",
    "cuda.memcpy_dtoh(host_output, device_output)\n",
    "\n",
    "#################### End GPU timing\n",
    "end_full_gpu.record()\n",
    "cuda.Context.synchronize()\n",
    "gpu_full_time = start_full_gpu.time_till(end_full_gpu)*1e-3\n",
    "gpu_kernel_time = start_full_gpu.time_till(end_kernel_gpu)*1e-3\n",
    "computation_full_time = start_computation_gpu.time_till(end_computation_gpu)*1e-3\n",
    "print(\"Full elapsed time using GPU (sec): \", gpu_full_time)\n",
    "print(\"---------------------\")\n",
    "print(\"Kernel creation and compile time using GPU (sec): \", gpu_kernel_time)\n",
    "print(\"---------------------\")\n",
    "print(\"Computation time using GPU (sec): \", computation_full_time)\n",
    "print(\"---------------------\")\n",
    "print(\"Memory management time using GPU (sec): \", gpu_full_time-gpu_kernel_time-computation_full_time)\n",
    "print(\"---------------------\")\n",
    "\n",
    "# Print result\n",
    "print(\"Original array:\", host_array)\n",
    "print(\"Array after left rotation:\", host_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89ff335-f8b0-4d9b-b2f2-43e578f33c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using sequential for-loop (sec):  0.0005023479461669922\n",
      "---------------------\n",
      "[6. 3. 4. ... 2. 9. 0.]\n"
     ]
    }
   ],
   "source": [
    "# CPU Sequential implementation (naive)\n",
    "\n",
    "#################### Start CPU timing\n",
    "start_cpu = time.time()\n",
    "\n",
    "naive_out = np.empty(input_size)\n",
    "for idx, item in enumerate(host_array):\n",
    "    naive_out[(idx-1)%input_size] = item\n",
    "    \n",
    "#################### End CPU timing\n",
    "end_cpu = time.time()\n",
    "cpu_time = end_cpu - start_cpu\n",
    "print(\"Elapsed time using sequential for-loop (sec): \", cpu_time)\n",
    "print(\"---------------------\")\n",
    "    \n",
    "print(naive_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecad58d-f8b5-46ea-b5c4-ae44382ec470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using pythonic way (sec):  0.00016188621520996094\n",
      "---------------------\n",
      "[6 3 4 ... 2 9 0]\n"
     ]
    }
   ],
   "source": [
    "# CPU sequential implementation (pythonic)\n",
    "\n",
    "#################### Start CPU timing\n",
    "start_cpu = time.time()\n",
    "\n",
    "pythonic_out = np.concatenate((host_array[1:], host_array[:1])) \n",
    "\n",
    "#################### End CPU timing\n",
    "end_cpu = time.time()\n",
    "cpu_time = end_cpu - start_cpu\n",
    "print(\"Elapsed time using pythonic way (sec): \", cpu_time)\n",
    "print(\"---------------------\")\n",
    "\n",
    "print(pythonic_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417db96d-4073-4872-afff-16ac673e8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output OK\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "# Compare the different implementations\n",
    "if (host_output == pythonic_out).all() and (pythonic_out == np.array(naive_out, dtype=np.int32)).all():\n",
    "    print(\"Output OK\")\n",
    "else:\n",
    "    print(\"Output do not match, please investigate!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6a39d-adc7-4548-9442-4d40c38a36db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
