{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5dc91d5-c618-4f0e-a31a-0b0271cf074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full elapsed time using GPU (ms):  0.9042239785194397\n",
      "---------------------\n",
      "Kernel creation and compile time using GPU (ms):  0.5723519921302795\n",
      "---------------------\n",
      "Computation time using GPU (ms):  0.10035199671983719\n",
      "---------------------\n",
      "Memory management time using GPU (ms):  0.23151998966932297\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "from pycuda.compiler import SourceModule\n",
    "import time \n",
    "\n",
    "# Initialize input array with size=1024 since it's the highest and allows us to see the more differences\n",
    "# We do not time this since it is the imput creation\n",
    "input_size = 1024\n",
    "host_array = np.random.randint(low=0, high=10, size=input_size, dtype=np.int32)\n",
    "\n",
    "start_full_gpu = cuda.Event()\n",
    "end_full_gpu = cuda.Event()\n",
    "end_kernel_gpu = cuda.Event()\n",
    "start_computation_gpu = cuda.Event()\n",
    "end_computation_gpu = cuda.Event()\n",
    "\n",
    "#################### Satrt GPU timing\n",
    "start_full_gpu.record()\n",
    "\n",
    "# CUDA kernel for left rotation\n",
    "kernel_code = \"\"\"\n",
    "__global__ void left_rotation(int *in, int *out, int size) {\n",
    "    // int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    // Since we assume that there's only one block with 1024 threads we can just use the following\n",
    "    int idx = threadIdx.x;\n",
    "    if (idx < size) {\n",
    "        int shifted_idx = (idx - 1 + size) % size;\n",
    "        out[shifted_idx] = in[idx];\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the CUDA kernel\n",
    "mod = SourceModule(kernel_code)\n",
    "left_rotation = mod.get_function(\"left_rotation\")\n",
    "\n",
    "#################### End kernel GPU timing\n",
    "end_kernel_gpu.record()\n",
    "\n",
    "# Allocate memory on GPU\n",
    "device_array = cuda.mem_alloc(host_array.nbytes)\n",
    "device_output = cuda.mem_alloc(host_array.nbytes)\n",
    "\n",
    "# Copy data to GPU\n",
    "cuda.memcpy_htod(device_array, host_array)\n",
    "\n",
    "# Define block and grid size\n",
    "# Since we assume only one block with 1024 threads\n",
    "block_size = input_size\n",
    "grid_size = 1\n",
    "\n",
    "#################### Start computation GPU timing\n",
    "start_computation_gpu.record()\n",
    "# Launch kernel\n",
    "left_rotation(device_array, device_output, np.int32(input_size), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "#################### End computation GPU timing\n",
    "end_computation_gpu.record()\n",
    "\n",
    "# Copy result back to CPU\n",
    "host_output = np.empty_like(host_array)\n",
    "cuda.memcpy_dtoh(host_output, device_output)\n",
    "\n",
    "#################### End GPU timing\n",
    "end_full_gpu.record()\n",
    "cuda.Context.synchronize()\n",
    "gpu_full_time = start_full_gpu.time_till(end_full_gpu)\n",
    "gpu_kernel_time = start_full_gpu.time_till(end_kernel_gpu)\n",
    "computation_full_time = start_computation_gpu.time_till(end_computation_gpu)\n",
    "print(\"Full elapsed time using GPU (ms): \", gpu_full_time)\n",
    "print(\"---------------------\")\n",
    "print(\"Kernel creation and compile time using GPU (ms): \", gpu_kernel_time)\n",
    "print(\"---------------------\")\n",
    "print(\"Computation time using GPU (ms): \", computation_full_time)\n",
    "print(\"---------------------\")\n",
    "print(\"Memory management time using GPU (ms): \", gpu_full_time-gpu_kernel_time-computation_full_time)\n",
    "print(\"---------------------\")\n",
    "\n",
    "# Print result\n",
    "#print(\"Original array:\", host_array)\n",
    "#print(\"Array after left rotation:\", host_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89ff335-f8b0-4d9b-b2f2-43e578f33c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using sequential for-loop (ms):  0.3058910369873047\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# CPU Sequential implementation (naive)\n",
    "\n",
    "#################### Start CPU timing\n",
    "start_cpu = time.time()\n",
    "\n",
    "naive_out = np.empty(input_size)\n",
    "for idx, item in enumerate(host_array):\n",
    "    naive_out[(idx-1)%input_size] = item\n",
    "    \n",
    "#################### End CPU timing\n",
    "end_cpu = time.time()\n",
    "cpu_time = (end_cpu - start_cpu)*1000\n",
    "print(\"Elapsed time using sequential for-loop (ms): \", cpu_time)\n",
    "print(\"---------------------\")\n",
    "    \n",
    "#print(naive_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecad58d-f8b5-46ea-b5c4-ae44382ec470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time using pythonic way (ms):  0.08845329284667969\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# CPU sequential implementation (pythonic)\n",
    "\n",
    "#################### Start CPU timing\n",
    "start_cpu = time.time()\n",
    "\n",
    "pythonic_out = np.concatenate((host_array[1:], host_array[:1])) \n",
    "\n",
    "#################### End CPU timing\n",
    "end_cpu = time.time()\n",
    "cpu_time = (end_cpu - start_cpu)*1000\n",
    "print(\"Elapsed time using pythonic way (ms): \", cpu_time)\n",
    "print(\"---------------------\")\n",
    "\n",
    "#print(pythonic_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417db96d-4073-4872-afff-16ac673e8def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output OK\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "# Compare the different implementations\n",
    "if (host_output == pythonic_out).all() and (pythonic_out == np.array(naive_out, dtype=np.int32)).all():\n",
    "    print(\"Output OK\")\n",
    "else:\n",
    "    print(\"Output do not match, please investigate!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
